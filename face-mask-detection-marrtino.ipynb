{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MARRtino face mask classifier\nThe purpose of my project is creating an image classifier that can recognize wether a person is wearing or not a face mask.\nThis notebook contains the code I wrote in order to load the face mask dataset and train my classifier explained step-by-step. You can find more in my github repository [here](https://github.com/ludocomito/marrtino-face-detection).","metadata":{}},{"cell_type":"markdown","source":"### Import and setup Weights & Biases","metadata":{}},{"cell_type":"markdown","source":"Weights & Biases is a platform commonly used for logging useful information about the training process of a model. Here it will be used to log the data about loss and accuracy during the training and validation phases of the model. You can find the results of my experiments [here](https://github.com/ludocomito/marrtino-face-detection/tree/main/training%20reports).\nThe following lines of code are responsible for installing wandb library and setting up the login and the connection to the Weights & Biases project.","metadata":{}},{"cell_type":"code","source":"# WandB – Install the W&B library\n!pip install wandb -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\n# API Key will be requested\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:55:33.397004Z","iopub.execute_input":"2022-07-24T15:55:33.397392Z","iopub.status.idle":"2022-07-24T15:55:43.150428Z","shell.execute_reply.started":"2022-07-24T15:55:33.397356Z","shell.execute_reply":"2022-07-24T15:55:43.149291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Starts the communication with the platform\nwandb.init(project=\"MARRtino-face-mask-recognition\", entity=\"ludocomito\")","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:05.864291Z","iopub.execute_input":"2022-07-24T15:56:05.865292Z","iopub.status.idle":"2022-07-24T15:56:08.818137Z","shell.execute_reply.started":"2022-07-24T15:56:05.865243Z","shell.execute_reply":"2022-07-24T15:56:08.817183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries used\nThe libraries involved in this project are:\n* Torch and Torchvision (framework used to create and train the model)\n* Numpy - used for array manipulation and math transforms\n* Matplotlib - used for displaying images and plots","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, random_split\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\ncudnn.benchmark = True\nplt.ion()   # interactive mode","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-24T17:27:40.996929Z","iopub.execute_input":"2022-07-24T17:27:40.997276Z","iopub.status.idle":"2022-07-24T17:27:41.006775Z","shell.execute_reply.started":"2022-07-24T17:27:40.997244Z","shell.execute_reply":"2022-07-24T17:27:41.005859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the dataset\nIn order to correctly import and process the dataset we have to choose the proper transforms. Here we define a pipeline of transform that will apply the following manipulations for each image:\n* Transforming the image into a tensor (turns it into an object that can be processed by a neural net)\n* Normalize the image (which means changing the range of pixel intensity values)\nThe dataset folder will be imported using the datasets.ImageFolder function, which handles for us the correct import of the photos and their labels.\n\n⚠️ *The ImageFolder function expects to have as an input a folder containing a sub-folder for every class. Each sub-folder should then contain the elements belonging to that class. Luckily our dataset already has this structure and does not require any change.*","metadata":{}},{"cell_type":"code","source":"# Defining the pipeline of transforms that will be applied to the images when creating the dataset.\ndata_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\ndata_dir = '../input/face-mask-detection/Dataset'\n\ndataset = torchvision.datasets.ImageFolder(data_dir,transform=data_transforms)\nprint(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:28:37.016499Z","iopub.execute_input":"2022-07-24T17:28:37.017111Z","iopub.status.idle":"2022-07-24T17:28:44.499545Z","shell.execute_reply.started":"2022-07-24T17:28:37.017074Z","shell.execute_reply":"2022-07-24T17:28:44.498404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we split the dataset into train and test sets. The proportion is 80% for training and 20% for validation.","metadata":{}},{"cell_type":"code","source":"train_set_size = int(len(dataset)*0.8)\nval_set_size = len(dataset) - train_set_size\ntrain, val = torch.utils.data.random_split(dataset, [train_set_size,val_set_size])","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:28:44.512100Z","iopub.execute_input":"2022-07-24T17:28:44.513138Z","iopub.status.idle":"2022-07-24T17:28:44.520207Z","shell.execute_reply.started":"2022-07-24T17:28:44.513055Z","shell.execute_reply":"2022-07-24T17:28:44.519234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining the data loader, which is combines a dataset and a sampler, and provides an iterable over the given dataset. The iterable will be used to parse the various batches during training and validation.\n\n","metadata":{}},{"cell_type":"code","source":"# Defining the data loaders for both sets\ntrain_loader = DataLoader(train, batch_size=64, shuffle=True)\nval_loader = DataLoader(val, batch_size=64, shuffle=True)\n\n# Creating the dataloaders object, which contains both the loaders\ndataloaders = {\"train\":train_loader,\"val\":val_loader}\ndataset_sizes = {\"train\": len(train), \"val\":len(val)}\n\n# Check that everything is correct\ndataloaders[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:28:44.523977Z","iopub.execute_input":"2022-07-24T17:28:44.524233Z","iopub.status.idle":"2022-07-24T17:28:44.531676Z","shell.execute_reply.started":"2022-07-24T17:28:44.524209Z","shell.execute_reply":"2022-07-24T17:28:44.530449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking that images and labels are represented correctly\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(type(images))\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:38.985712Z","iopub.execute_input":"2022-07-24T15:56:38.986056Z","iopub.status.idle":"2022-07-24T15:56:39.526274Z","shell.execute_reply.started":"2022-07-24T15:56:38.986026Z","shell.execute_reply":"2022-07-24T15:56:39.524423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining an helper function that shows the batch of images\nAfter the transformation, images are represented as tensors. The imshow function is helpful in order when we want to turn them back to readable images and show them in a plot.","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0)) # permuting the axes in the correct order\n    mean = np.array([0.5, 0.5, 0.5])\n    std = np.array([0.5, 0.5, 0.5])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(inp)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(train_loader))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:41.880173Z","iopub.execute_input":"2022-07-24T15:56:41.882950Z","iopub.status.idle":"2022-07-24T15:56:43.151301Z","shell.execute_reply.started":"2022-07-24T15:56:41.882902Z","shell.execute_reply":"2022-07-24T15:56:43.150282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model\nThe following is the function responsible for training the model. It runs for _num_epochs_ times (default is 25) and for each step runs a training and validation phase, computing the loss and performing backpropagation in order to update the model's weights.\nAt the end of the execution it will store the model with the best accuracy performing a deep copy into the final output model.","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    \n    # Measuring the time it takes to train\n    since = time.time()\n    \n    # Starting W&B logging\n    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            #send data to W&B\n            train_log(epoch_loss, epoch_acc,epoch,phase)\n            \n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:48.944144Z","iopub.execute_input":"2022-07-24T15:56:48.944579Z","iopub.status.idle":"2022-07-24T15:56:48.964002Z","shell.execute_reply.started":"2022-07-24T15:56:48.944541Z","shell.execute_reply":"2022-07-24T15:56:48.962808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function simply sends logging data to W&B classified by phase.\n\ndef train_log(loss, acc, epoch, phase):\n    loss = float(loss)\n    acc = float(acc)\n    \n    if phase == 'train':\n        wandb.log({\"Epoch\":epoch, \"Training loss\":loss, \"Training accuracy\": acc})\n    else:\n        wandb.log({\"Epoch\":epoch, \"Validation loss\":loss, \"Validation accuracy\": acc})","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:53.834272Z","iopub.execute_input":"2022-07-24T15:56:53.834888Z","iopub.status.idle":"2022-07-24T15:56:53.846326Z","shell.execute_reply.started":"2022-07-24T15:56:53.834849Z","shell.execute_reply":"2022-07-24T15:56:53.841878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the results\nThe visualize_model function runs a test on a batch of six images in order to see the model's predictions.","metadata":{}},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    \n    # Setting the model in eval mode in order to compute predictions\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n    \n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:55.859913Z","iopub.execute_input":"2022-07-24T15:56:55.860371Z","iopub.status.idle":"2022-07-24T15:56:55.872623Z","shell.execute_reply.started":"2022-07-24T15:56:55.860336Z","shell.execute_reply":"2022-07-24T15:56:55.871543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the model and running the training\nHere we execute the functions previously defined. Firs we import the ResNet18 model (which has been tested both pre-trained and not pre-trained). We now need to choose a criterion and an optimizer.\nThe criterion corresponds to the function that we use in order to measure the loss of our model. In this case we use CrossEntropyLoss. Here is a brief definition. \n> Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label.\n\nThe optimizer defines the function that we will use in order to updated the weights in order to reduce the loss. Here we use SGD (Stochastic Gradient Descent).\n\nThe last thing we define is the learning rate. As you will notice, I did not define a fixed learning rate. Instead I followed very popular technique which is defining a Learning Rate Scheduler. Practically it starts with a certain learning rate, and decreases it each *step_size* epochs in order to fine tune the more and more with the increasing of epochs.\n\n","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# The fc property of a model defines the size of the final layer, which should be equal to the number of classes\nclass_names = dataset.classes\nmodel_ft.fc = nn.Linear(num_ftrs, len(class_names))\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:56:59.160102Z","iopub.execute_input":"2022-07-24T15:56:59.160847Z","iopub.status.idle":"2022-07-24T15:57:03.050606Z","shell.execute_reply.started":"2022-07-24T15:56:59.160807Z","shell.execute_reply":"2022-07-24T15:57:03.049517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start training\nmodel_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:57:03.735821Z","iopub.execute_input":"2022-07-24T15:57:03.737562Z","iopub.status.idle":"2022-07-24T16:07:30.465468Z","shell.execute_reply.started":"2022-07-24T15:57:03.737512Z","shell.execute_reply":"2022-07-24T16:07:30.460418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See a sample of results\nvisualize_model(model_ft)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T10:30:36.816654Z","iopub.execute_input":"2022-07-24T10:30:36.817582Z","iopub.status.idle":"2022-07-24T10:30:38.724875Z","shell.execute_reply.started":"2022-07-24T10:30:36.817542Z","shell.execute_reply":"2022-07-24T10:30:38.723832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\ntorch.save(model_ft.state_dict(), 'mask_recognition_model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T10:56:44.484496Z","iopub.execute_input":"2022-07-24T10:56:44.484886Z","iopub.status.idle":"2022-07-24T10:56:44.568281Z","shell.execute_reply.started":"2022-07-24T10:56:44.484854Z","shell.execute_reply":"2022-07-24T10:56:44.567300Z"},"trusted":true},"execution_count":null,"outputs":[]}]}